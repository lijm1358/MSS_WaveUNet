{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FzflK4fL2ll",
        "outputId": "69a32f06-c0f4-4223-b6ed-d3da18bf8e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0s1QHuPL3qr",
        "outputId": "19b63686-413b-4764-eeff-1deb16981406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeApTPxNvL3Y",
        "outputId": "31a33de1-0204-4ebd-bd72-64a35bb65f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "94kdUPk-LzsA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import subprocess\n",
        "from subprocess import call\n",
        "from functools import partial\n",
        "\n",
        "import librosa\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import pad\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchmetrics.audio import SignalDistortionRatio as SDR\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pydub "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHRoNfiqLzsC"
      },
      "outputs": [],
      "source": [
        "# path_folder_in = '/content/gdrive/MyDrive/musdb18/test'\n",
        "# path_folder_out = '/content/gdrive/MyDrive/createdmusdb18/test'\n",
        "# \n",
        "# \n",
        "# \n",
        "# files = os.listdir(path_folder_in)\n",
        "# for file in tqdm(files, position=0, leave=True):\n",
        "#   # tqdm.write(f\"current song : {file}\")\n",
        "#   file_in = path_folder_in + '/' + file\n",
        "#   for i in range(5):\n",
        "#     filesp = file.split(\".\")\n",
        "#     filesp[-1] = f\"{i}.mp3\"\n",
        "#     filesp = \".\".join(filesp)\n",
        "#     file_out = f\"{path_folder_out}/{filesp}\"\n",
        "#     # tqdm.write(f\"processing {file_out}\", end='\\r')\n",
        "#     call(('ffmpeg', '-y', '-i', file_in, '-map', f'0:{i}', '-vn', file_out),\n",
        "#          stdout=subprocess.DEVNULL,\n",
        "#          stderr=subprocess.STDOUT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/gdrive/MyDrive/createdmusdb18/train/data_numpy'\n",
        "target_path = '/content/gdrive/MyDrive/createdmusdb18/train/data_numpy_split'\n",
        "song_np_full = []\n",
        "count = 0\n",
        "for i, filename in enumerate(tqdm(os.listdir(train_path))):\n",
        "    song_np = np.load(os.path.join(train_path, filename))\n",
        "    song_np_full.append(song_np)\n",
        "    if i%5==4:\n",
        "        song_np_full = np.stack(song_np_full)\n",
        "        index = 0\n",
        "        while index+16384 <= song_np_full.shape[1]:\n",
        "            np.save(os.path.join(target_path, str(count)), song_np_full[:, index:index+16384])\n",
        "            index+=16384\n",
        "            count+=1\n",
        "        song_np_full = []"
      ],
      "metadata": {
        "id": "jw2g-pCOsE6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5babe083-22f9-451c-cdb8-e1265ff18c9b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [13:11<00:00,  1.58s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "X7N0hkaCLzsD"
      },
      "outputs": [],
      "source": [
        "class MUSDBDataset(Dataset):\n",
        "    def __init__(self, data_dir: str, train:bool=True):\n",
        "        self.music_fulllist = []\n",
        "        self.music_list = []\n",
        "        self.sep_list = []\n",
        "        self.data_size = 500 if train is True else 250\n",
        "        self.train = train\n",
        "        self.crop_size = 284672\n",
        "        if train:\n",
        "            self.data_dir = os.path.join(data_dir, 'data_numpy_split')\n",
        "        else:\n",
        "            self.data_dir = os.path.join(data_dir, 'data_numpy')\n",
        "        # if not os.path.exists(self.data_dir) or \\\n",
        "        #     len([name for name in os.listdir(self.data_dir)]) < self.data_size:\n",
        "        #     print(\"Data has not been saved as numpy object. Converting...\")\n",
        "        #     if not os.path.exists(self.data_dir):\n",
        "        #         os.makedirs(self.data_dir)\n",
        "        #     self.convert_to_numpy(data_dir, self.data_dir)\n",
        "        self.music_fulllist = self.get_filenames(self.data_dir)\n",
        "        if not train:\n",
        "            self.music_list, self.sep_list = self.separate_source(self.music_fulllist)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.music_fulllist) if self.train else len(self.music_list)\n",
        "        #return len(self.music_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            music = self.music_fulllist[idx]\n",
        "            music = np.load(music)\n",
        "            return np.expand_dims(music[0], 0), music[1:]\n",
        "        else:\n",
        "            base_music = self.music_list[idx]\n",
        "            base_music = np.load(base_music)\n",
        "            base_music = np.stack([base_music[:self.crop_size]])\n",
        "\n",
        "            sep_music = self.sep_list[idx*4 : idx*4+4]\n",
        "            sep_music = np.stack([np.load(idx)[:self.crop_size] for idx in sep_music])\n",
        "            return base_music, sep_music\n",
        "\n",
        "    def get_filenames(self, path):\n",
        "        files_list = list()\n",
        "        for filename in os.listdir(path):\n",
        "            files_list.append(os.path.join(path, filename))\n",
        "        return files_list\n",
        "\n",
        "    def convert_to_numpy(self, music_dir, target_dir):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        music_list = self.get_filenames(music_dir)\n",
        "        for music in tqdm(music_list):\n",
        "            outfile_name = music.split(\"/\")[-1]\n",
        "            outfile_name = target_dir + \"/\" + outfile_name\n",
        "            arr, _ = librosa.load(music)\n",
        "            np.save(outfile_name, arr)\n",
        "\n",
        "    def separate_source(self, mus_list):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        music_list = list()\n",
        "        sep_list = list()\n",
        "        for music in tqdm(mus_list):\n",
        "            mus_type = music.split(\".\")[-3]\n",
        "            if mus_type == '0':\n",
        "                music_list.append(music)\n",
        "            else:\n",
        "                sep_list.append(music)\n",
        "\n",
        "        return music_list, sep_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "htj5Z8MpLzsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9dc23ba-d3f8-4571-ccb5-4e88748d5fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [00:00<00:00, 765943.02it/s]\n"
          ]
        }
      ],
      "source": [
        "# train_ds = MUSDBDataset('/content/gdrive/MyDrive/createdmusdb18/train')\n",
        "train_ds = MUSDBDataset('/content/gdrive/MyDrive/createdmusdb18/train')\n",
        "test_ds = MUSDBDataset('/content/gdrive/MyDrive/createdmusdb18/test', train=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Rwwhvf3eno",
        "outputId": "9960ed99-fd2e-4726-d5f4-3d13ca31cbe1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 16384)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds[0][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7vrankSDrJ4",
        "outputId": "ebb9e4bf-2224-4ec5-8bce-e9ab0b0aef1f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 284672)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "0XBPVV1sLzsF"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_ds, batch_size=16)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3m3_EPkjLzsF"
      },
      "outputs": [],
      "source": [
        "class DownSampling(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=24, kernel_size=15):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(in_ch, out_ch, kernel_size=kernel_size, padding=7),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv1d(out_ch, out_ch, kernel_size=kernel_size, padding=7),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x: Tensor):\n",
        "        x = self.net(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "khmjRe9-LzsG"
      },
      "outputs": [],
      "source": [
        "class UpSampling(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size):\n",
        "        super().__init__()\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode=\"linear\", align_corners=True)\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_ch, out_ch, kernel_size=kernel_size, padding=2),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv1d(out_ch, out_ch, kernel_size=kernel_size, padding=2),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, x_back):\n",
        "        x = self.upsample(x);\n",
        "        diff = x_back.shape[-1] - x.shape[-1]\n",
        "        x = pad(x, (0, diff))\n",
        "        x = torch.cat([x, x_back], axis=1)\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "LOe36a_mLzsH"
      },
      "outputs": [],
      "source": [
        "class WaveUNet(nn.Module):\n",
        "    def __init__(self, n_level=12, n_source=4):\n",
        "        super().__init__()\n",
        "        self.level = n_level\n",
        "        \n",
        "        layers=[DownSampling(in_ch=1,out_ch=24,kernel_size=15)]\n",
        "        \n",
        "        for i in range(self.level-1):\n",
        "            layers.append(DownSampling(in_ch=24*(i+1),out_ch=24*(i+2),kernel_size=15))\n",
        "            \n",
        "        # layers.append(DownSampling(in_ch=24*(self.level), out_ch=24*(self.level+1), kernel_size=15, decimate=False))\n",
        "        layers.append(DownSampling(in_ch=24*(self.level), out_ch=24*(self.level+1), kernel_size=15))\n",
        "            \n",
        "        for i in range(self.level):\n",
        "            layers.append(UpSampling(in_ch=24*(self.level+1-i) + 24*(self.level - i), out_ch=24*(self.level-i), kernel_size=5))\n",
        "            \n",
        "        self.net = nn.ModuleList(layers)\n",
        "        self.separation = nn.Sequential(\n",
        "            nn.Conv1d(25, n_source, kernel_size=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv1d(n_source, n_source, kernel_size=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: Tensor):\n",
        "        layer_to_concat = []\n",
        "        # print(\"before in \", x.shape)\n",
        "        layer_to_concat.append(x)\n",
        "        for layer in self.net[0: self.level]:\n",
        "            x = layer(x)\n",
        "            # print(\"conv \", x.shape)\n",
        "            layer_to_concat.append(x)\n",
        "            x = x[:, :, 1::2]\n",
        "            # print(\"decimate \", x.shape)\n",
        "        x = self.net[self.level](x)\n",
        "        # print(\"middle out \", x.shape)\n",
        "        layer_to_concat.append(x)\n",
        "        for i, layer in enumerate(self.net[self.level+1:]):\n",
        "            # print(\"before up \", x.shape)\n",
        "            x = layer_to_concat[-1]\n",
        "            x = layer(x, layer_to_concat[-1-i-1])\n",
        "            # print(\"after up \", x.shape)\n",
        "            layer_to_concat[-1] = x\n",
        "            \n",
        "        x = torch.cat([layer_to_concat[0], x], axis=1)\n",
        "        x = self.separation(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "rwTtpsAdLzsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50dee6d2-5daf-4094-e4ca-e811f5b2fff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "wJcJkej6LzsI"
      },
      "outputs": [],
      "source": [
        "model = WaveUNet(n_level=12).to(device)\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "L0646__YLzsI"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "test_loss = SDR().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=[0.9, 0.999])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "p9ikop1ULzsJ"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch*len(X) % 800 == 0:\n",
        "            print(f\"loss : {loss.item()} ({batch*len(X)}/{size})\")\n",
        "\n",
        "        del pred\n",
        "        del loss\n",
        "        del X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "zwZK5M1c18F4"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "    test_loss /= len(dataloader)\n",
        "    print(f\"Test loss : {test_loss}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "3MhFHqZwLzsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ceb53c04-eb88-447a-f8b4-7b569879b7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1\n",
            "---------------------------\n",
            "loss : 0.03301911801099777 (0/30729)\n",
            "loss : 0.017839204519987106 (800/30729)\n",
            "loss : 0.0002462365082465112 (1600/30729)\n",
            "loss : 0.0040946477092802525 (2400/30729)\n",
            "loss : 0.002815782791003585 (3200/30729)\n",
            "loss : 0.004637870471924543 (4000/30729)\n",
            "loss : 0.0006262432434596121 (4800/30729)\n",
            "loss : 0.0029275156557559967 (5600/30729)\n",
            "loss : 0.0006390626076608896 (6400/30729)\n",
            "loss : 0.005832795985043049 (7200/30729)\n",
            "loss : 0.006514036096632481 (8000/30729)\n",
            "loss : 0.0031051423866301775 (8800/30729)\n",
            "loss : 0.0035126020666211843 (9600/30729)\n",
            "loss : 0.002043253742158413 (10400/30729)\n",
            "loss : 0.002908873837441206 (11200/30729)\n",
            "loss : 0.003960856236517429 (12000/30729)\n",
            "loss : 0.001287031453102827 (12800/30729)\n",
            "loss : 0.0011831902666017413 (13600/30729)\n",
            "loss : 0.0051181623712182045 (14400/30729)\n",
            "loss : 0.004767945036292076 (15200/30729)\n",
            "loss : 0.0015862714499235153 (16000/30729)\n",
            "loss : 0.0002297628961969167 (16800/30729)\n",
            "loss : 0.0004441766650415957 (17600/30729)\n",
            "loss : 0.002894776174798608 (18400/30729)\n",
            "loss : 0.0014957062667235732 (19200/30729)\n",
            "loss : 0.0027176309376955032 (20000/30729)\n",
            "loss : 0.0019026572117581964 (20800/30729)\n",
            "loss : 0.004460720345377922 (21600/30729)\n",
            "loss : 0.003823383478447795 (22400/30729)\n",
            "loss : 0.005695991683751345 (23200/30729)\n",
            "loss : 0.0011279287282377481 (24000/30729)\n",
            "loss : 0.003185170702636242 (24800/30729)\n",
            "loss : 0.0019184912089258432 (25600/30729)\n",
            "loss : 0.004295739810913801 (26400/30729)\n",
            "loss : 0.0025692007038742304 (27200/30729)\n",
            "loss : 1.1983143849647604e-05 (28000/30729)\n",
            "loss : 0.004360870458185673 (28800/30729)\n",
            "loss : 0.004100615158677101 (29600/30729)\n",
            "loss : 0.003153573488816619 (30400/30729)\n",
            "Test loss : 0.0010357340070186183\n",
            "\n",
            "epoch : 2\n",
            "---------------------------\n",
            "loss : 0.003119459142908454 (0/30729)\n",
            "loss : 0.0025704463478177786 (800/30729)\n",
            "loss : 0.00018273602472618222 (1600/30729)\n",
            "loss : 0.0036027298774570227 (2400/30729)\n",
            "loss : 0.0023692375980317593 (3200/30729)\n",
            "loss : 0.0033541349694132805 (4000/30729)\n",
            "loss : 0.000672091031447053 (4800/30729)\n",
            "loss : 0.0024910112842917442 (5600/30729)\n",
            "loss : 0.000629425689112395 (6400/30729)\n",
            "loss : 0.004472002852708101 (7200/30729)\n",
            "loss : 0.004409109242260456 (8000/30729)\n",
            "loss : 0.002847508294507861 (8800/30729)\n",
            "loss : 0.0030753479804843664 (9600/30729)\n",
            "loss : 0.0014269278617575765 (10400/30729)\n",
            "loss : 0.0025725956074893475 (11200/30729)\n",
            "loss : 0.0031720222905278206 (12000/30729)\n",
            "loss : 0.0009620267665013671 (12800/30729)\n",
            "loss : 0.001172527321614325 (13600/30729)\n",
            "loss : 0.0047348132357001305 (14400/30729)\n",
            "loss : 0.004324029665440321 (15200/30729)\n",
            "loss : 0.0013206100556999445 (16000/30729)\n",
            "loss : 0.00022559496574103832 (16800/30729)\n",
            "loss : 0.0004337173595558852 (17600/30729)\n",
            "loss : 0.00252741202712059 (18400/30729)\n",
            "loss : 0.0013650101609528065 (19200/30729)\n",
            "loss : 0.0025780200958251953 (20000/30729)\n",
            "loss : 0.001874995417892933 (20800/30729)\n",
            "loss : 0.004152281675487757 (21600/30729)\n",
            "loss : 0.003368785372003913 (22400/30729)\n",
            "loss : 0.005385984666645527 (23200/30729)\n",
            "loss : 0.0010028959950432181 (24000/30729)\n",
            "loss : 0.003073751460760832 (24800/30729)\n",
            "loss : 0.0016966512193903327 (25600/30729)\n",
            "loss : 0.0039367638528347015 (26400/30729)\n",
            "loss : 0.002480753231793642 (27200/30729)\n",
            "loss : 8.256472028733697e-06 (28000/30729)\n",
            "loss : 0.004109201952815056 (28800/30729)\n",
            "loss : 0.003967301920056343 (29600/30729)\n",
            "loss : 0.0028274725191295147 (30400/30729)\n",
            "Test loss : 0.0009747026779223233\n",
            "\n",
            "epoch : 3\n",
            "---------------------------\n",
            "loss : 0.0023927674628794193 (0/30729)\n",
            "loss : 0.0021806866861879826 (800/30729)\n",
            "loss : 0.00018078795983456075 (1600/30729)\n",
            "loss : 0.0036303671076893806 (2400/30729)\n",
            "loss : 0.002175999339669943 (3200/30729)\n",
            "loss : 0.0031207825522869825 (4000/30729)\n",
            "loss : 0.0006564927753061056 (4800/30729)\n",
            "loss : 0.002479386515915394 (5600/30729)\n",
            "loss : 0.0006229561986401677 (6400/30729)\n",
            "loss : 0.004643671214580536 (7200/30729)\n",
            "loss : 0.004469849169254303 (8000/30729)\n",
            "loss : 0.0028134894091635942 (8800/30729)\n",
            "loss : 0.002915091346949339 (9600/30729)\n",
            "loss : 0.0014557200483977795 (10400/30729)\n",
            "loss : 0.0026378100737929344 (11200/30729)\n",
            "loss : 0.0030744795221835375 (12000/30729)\n",
            "loss : 0.0009934173431247473 (12800/30729)\n",
            "loss : 0.0011559765553101897 (13600/30729)\n",
            "loss : 0.004797108471393585 (14400/30729)\n",
            "loss : 0.004329409450292587 (15200/30729)\n",
            "loss : 0.0013288998743519187 (16000/30729)\n",
            "loss : 0.00022387783974409103 (16800/30729)\n",
            "loss : 0.0004492267034947872 (17600/30729)\n",
            "loss : 0.0025720647536218166 (18400/30729)\n",
            "loss : 0.0014047101140022278 (19200/30729)\n",
            "loss : 0.0025352761149406433 (20000/30729)\n",
            "loss : 0.001882926095277071 (20800/30729)\n",
            "loss : 0.004111291375011206 (21600/30729)\n",
            "loss : 0.0033778618089854717 (22400/30729)\n",
            "loss : 0.00529923802241683 (23200/30729)\n",
            "loss : 0.0010117958299815655 (24000/30729)\n",
            "loss : 0.003053497988730669 (24800/30729)\n",
            "loss : 0.0018399666296318173 (25600/30729)\n",
            "loss : 0.003936057910323143 (26400/30729)\n",
            "loss : 0.002408150117844343 (27200/30729)\n",
            "loss : 6.216081601451151e-06 (28000/30729)\n",
            "loss : 0.003923014272004366 (28800/30729)\n",
            "loss : 0.0039301649667322636 (29600/30729)\n",
            "loss : 0.002767540281638503 (30400/30729)\n",
            "Test loss : 0.0010037444008048624\n",
            "\n",
            "epoch : 4\n",
            "---------------------------\n",
            "loss : 0.002202699426561594 (0/30729)\n",
            "loss : 0.0020586131140589714 (800/30729)\n",
            "loss : 0.00017660646699368954 (1600/30729)\n",
            "loss : 0.0036110891960561275 (2400/30729)\n",
            "loss : 0.0021349231246858835 (3200/30729)\n",
            "loss : 0.0029938635416328907 (4000/30729)\n",
            "loss : 0.0006201565265655518 (4800/30729)\n",
            "loss : 0.002360255690291524 (5600/30729)\n",
            "loss : 0.000587601971346885 (6400/30729)\n",
            "loss : 0.004713087342679501 (7200/30729)\n",
            "loss : 0.004553103819489479 (8000/30729)\n",
            "loss : 0.002585724228993058 (8800/30729)\n",
            "loss : 0.002980167279019952 (9600/30729)\n",
            "loss : 0.0015300901141017675 (10400/30729)\n",
            "loss : 0.002552828984335065 (11200/30729)\n",
            "loss : 0.0029461162630468607 (12000/30729)\n",
            "loss : 0.0010480138007551432 (12800/30729)\n",
            "loss : 0.0008842918905429542 (13600/30729)\n",
            "loss : 0.00449084397405386 (14400/30729)\n",
            "loss : 0.003917803056538105 (15200/30729)\n",
            "loss : 0.0012521904427558184 (16000/30729)\n",
            "loss : 0.0001944020768860355 (16800/30729)\n",
            "loss : 0.0004618217935785651 (17600/30729)\n",
            "loss : 0.0023011094890534878 (18400/30729)\n",
            "loss : 0.001165086287073791 (19200/30729)\n",
            "loss : 0.0020497513469308615 (20000/30729)\n",
            "loss : 0.001456022378988564 (20800/30729)\n",
            "loss : 0.0033642221242189407 (21600/30729)\n",
            "loss : 0.0030274726450443268 (22400/30729)\n",
            "loss : 0.005149157717823982 (23200/30729)\n",
            "loss : 0.0010283878073096275 (24000/30729)\n",
            "loss : 0.0025041343178600073 (24800/30729)\n",
            "loss : 0.0018740722443908453 (25600/30729)\n",
            "loss : 0.0035541041288524866 (26400/30729)\n",
            "loss : 0.0021153707057237625 (27200/30729)\n",
            "loss : 3.9342739910352975e-06 (28000/30729)\n",
            "loss : 0.003474254161119461 (28800/30729)\n",
            "loss : 0.0034327541943639517 (29600/30729)\n",
            "loss : 0.002683288650587201 (30400/30729)\n",
            "Test loss : 0.0009522618929622695\n",
            "\n",
            "epoch : 5\n",
            "---------------------------\n",
            "loss : 0.002064503263682127 (0/30729)\n",
            "loss : 0.0019587036222219467 (800/30729)\n",
            "loss : 0.00022518049809150398 (1600/30729)\n",
            "loss : 0.003119287546724081 (2400/30729)\n",
            "loss : 0.0019458766328170896 (3200/30729)\n",
            "loss : 0.002660156227648258 (4000/30729)\n",
            "loss : 0.0005425313720479608 (4800/30729)\n",
            "loss : 0.0019425572827458382 (5600/30729)\n",
            "loss : 0.00046000740258023143 (6400/30729)\n",
            "loss : 0.0043912893161177635 (7200/30729)\n",
            "loss : 0.0044952817261219025 (8000/30729)\n",
            "loss : 0.0021737616043537855 (8800/30729)\n",
            "loss : 0.0025918828323483467 (9600/30729)\n",
            "loss : 0.001465711509808898 (10400/30729)\n",
            "loss : 0.002112430753186345 (11200/30729)\n",
            "loss : 0.002550642006099224 (12000/30729)\n",
            "loss : 0.0010599286761134863 (12800/30729)\n",
            "loss : 0.0007797943544574082 (13600/30729)\n",
            "loss : 0.004071669653058052 (14400/30729)\n",
            "loss : 0.0035187897738069296 (15200/30729)\n",
            "loss : 0.0012270407751202583 (16000/30729)\n",
            "loss : 0.00017550258780829608 (16800/30729)\n",
            "loss : 0.00040464807534590364 (17600/30729)\n",
            "loss : 0.0021557053551077843 (18400/30729)\n",
            "loss : 0.0011472139740362763 (19200/30729)\n",
            "loss : 0.002006987575441599 (20000/30729)\n",
            "loss : 0.0013372881803661585 (20800/30729)\n",
            "loss : 0.00310697453096509 (21600/30729)\n",
            "loss : 0.0030252141878008842 (22400/30729)\n",
            "loss : 0.00429387716576457 (23200/30729)\n",
            "loss : 0.0008763755904510617 (24000/30729)\n",
            "loss : 0.0023137901443988085 (24800/30729)\n",
            "loss : 0.0019323190208524466 (25600/30729)\n",
            "loss : 0.0033647874370217323 (26400/30729)\n",
            "loss : 0.002088078297674656 (27200/30729)\n",
            "loss : 4.330977390054613e-06 (28000/30729)\n",
            "loss : 0.0033767884597182274 (28800/30729)\n",
            "loss : 0.003411527257412672 (29600/30729)\n",
            "loss : 0.002579585649073124 (30400/30729)\n",
            "Test loss : 0.0009373902867082506\n",
            "\n",
            "epoch : 6\n",
            "---------------------------\n",
            "loss : 0.0017797145992517471 (0/30729)\n",
            "loss : 0.0019461732590571046 (800/30729)\n",
            "loss : 0.00020490356837399304 (1600/30729)\n",
            "loss : 0.0029550010804086924 (2400/30729)\n",
            "loss : 0.001985381357371807 (3200/30729)\n",
            "loss : 0.0025386293418705463 (4000/30729)\n",
            "loss : 0.000501781003549695 (4800/30729)\n",
            "loss : 0.001812314847484231 (5600/30729)\n",
            "loss : 0.00047403553617186844 (6400/30729)\n",
            "loss : 0.004339441657066345 (7200/30729)\n",
            "loss : 0.004606070928275585 (8000/30729)\n",
            "loss : 0.002026711590588093 (8800/30729)\n",
            "loss : 0.0025180126540362835 (9600/30729)\n",
            "loss : 0.0014993402874097228 (10400/30729)\n",
            "loss : 0.0020665740594267845 (11200/30729)\n",
            "loss : 0.0024050758220255375 (12000/30729)\n",
            "loss : 0.0010227542370557785 (12800/30729)\n",
            "loss : 0.0007210369221866131 (13600/30729)\n",
            "loss : 0.00390838086605072 (14400/30729)\n",
            "loss : 0.0034039414022117853 (15200/30729)\n",
            "loss : 0.0012432725634425879 (16000/30729)\n",
            "loss : 0.00017304642824456096 (16800/30729)\n",
            "loss : 0.000385661784093827 (17600/30729)\n",
            "loss : 0.002110476139932871 (18400/30729)\n",
            "loss : 0.0011122773867100477 (19200/30729)\n",
            "loss : 0.001986177172511816 (20000/30729)\n",
            "loss : 0.0012398870894685388 (20800/30729)\n",
            "loss : 0.003077257424592972 (21600/30729)\n",
            "loss : 0.0030126452911645174 (22400/30729)\n",
            "loss : 0.004204520955681801 (23200/30729)\n",
            "loss : 0.000884158187545836 (24000/30729)\n",
            "loss : 0.002257008571177721 (24800/30729)\n",
            "loss : 0.0016561157535761595 (25600/30729)\n",
            "loss : 0.003291899571195245 (26400/30729)\n",
            "loss : 0.002045016037300229 (27200/30729)\n",
            "loss : 4.0388486013398506e-06 (28000/30729)\n",
            "loss : 0.0032621196005493402 (28800/30729)\n",
            "loss : 0.0033833258785307407 (29600/30729)\n",
            "loss : 0.0024945130571722984 (30400/30729)\n",
            "Test loss : 0.0009426288161193952\n",
            "\n",
            "epoch : 7\n",
            "---------------------------\n",
            "loss : 0.001653423416428268 (0/30729)\n",
            "loss : 0.001927138539031148 (800/30729)\n",
            "loss : 0.00023448413412552327 (1600/30729)\n",
            "loss : 0.002894700039178133 (2400/30729)\n",
            "loss : 0.0019457782618701458 (3200/30729)\n",
            "loss : 0.002457113703712821 (4000/30729)\n",
            "loss : 0.0005094766383990645 (4800/30729)\n",
            "loss : 0.0018914303509518504 (5600/30729)\n",
            "loss : 0.00045413398765958846 (6400/30729)\n",
            "loss : 0.004328371956944466 (7200/30729)\n",
            "loss : 0.004659304860979319 (8000/30729)\n",
            "loss : 0.001969873206689954 (8800/30729)\n",
            "loss : 0.002503424184396863 (9600/30729)\n",
            "loss : 0.0015290015144273639 (10400/30729)\n",
            "loss : 0.002075075637549162 (11200/30729)\n",
            "loss : 0.002293693833053112 (12000/30729)\n",
            "loss : 0.001033034292049706 (12800/30729)\n",
            "loss : 0.0007084985263645649 (13600/30729)\n",
            "loss : 0.003856974421069026 (14400/30729)\n",
            "loss : 0.003361270995810628 (15200/30729)\n",
            "loss : 0.0012254588073119521 (16000/30729)\n",
            "loss : 0.00018069855286739767 (16800/30729)\n",
            "loss : 0.00038378723547793925 (17600/30729)\n",
            "loss : 0.0020294804126024246 (18400/30729)\n",
            "loss : 0.00111555983312428 (19200/30729)\n",
            "loss : 0.0019478395115584135 (20000/30729)\n",
            "loss : 0.00118282251060009 (20800/30729)\n",
            "loss : 0.002908817958086729 (21600/30729)\n",
            "loss : 0.0030018161050975323 (22400/30729)\n",
            "loss : 0.004111529793590307 (23200/30729)\n",
            "loss : 0.0008861440001055598 (24000/30729)\n",
            "loss : 0.002209179103374481 (24800/30729)\n",
            "loss : 0.001483432948589325 (25600/30729)\n",
            "loss : 0.003244095016270876 (26400/30729)\n",
            "loss : 0.002045509871095419 (27200/30729)\n",
            "loss : 4.6407999434450176e-06 (28000/30729)\n",
            "loss : 0.003300851210951805 (28800/30729)\n",
            "loss : 0.003293087240308523 (29600/30729)\n",
            "loss : 0.0025110989809036255 (30400/30729)\n",
            "Test loss : 0.000953311551711522\n",
            "\n",
            "epoch : 8\n",
            "---------------------------\n",
            "loss : 0.0015599976759403944 (0/30729)\n",
            "loss : 0.001911928877234459 (800/30729)\n",
            "loss : 0.0002477724337950349 (1600/30729)\n",
            "loss : 0.0027921139262616634 (2400/30729)\n",
            "loss : 0.0019832169637084007 (3200/30729)\n",
            "loss : 0.0024898110423237085 (4000/30729)\n",
            "loss : 0.0005137620028108358 (4800/30729)\n",
            "loss : 0.0017042960971593857 (5600/30729)\n",
            "loss : 0.0004576772917062044 (6400/30729)\n",
            "loss : 0.004290898330509663 (7200/30729)\n",
            "loss : 0.0046701617538928986 (8000/30729)\n",
            "loss : 0.0019193915650248528 (8800/30729)\n",
            "loss : 0.002660455647855997 (9600/30729)\n",
            "loss : 0.0015390256885439157 (10400/30729)\n",
            "loss : 0.0020455322228372097 (11200/30729)\n",
            "loss : 0.002239760011434555 (12000/30729)\n",
            "loss : 0.0010210484033450484 (12800/30729)\n",
            "loss : 0.0007021690253168344 (13600/30729)\n",
            "loss : 0.0038245022296905518 (14400/30729)\n",
            "loss : 0.0033262690994888544 (15200/30729)\n",
            "loss : 0.0012114564888179302 (16000/30729)\n",
            "loss : 0.0001333738910034299 (16800/30729)\n",
            "loss : 0.00039377130451612175 (17600/30729)\n",
            "loss : 0.002033284865319729 (18400/30729)\n",
            "loss : 0.0011011239839717746 (19200/30729)\n",
            "loss : 0.0018993702251464128 (20000/30729)\n",
            "loss : 0.0010650468757376075 (20800/30729)\n",
            "loss : 0.002595469355583191 (21600/30729)\n",
            "loss : 0.003017461858689785 (22400/30729)\n",
            "loss : 0.003960030153393745 (23200/30729)\n",
            "loss : 0.0008814232423901558 (24000/30729)\n",
            "loss : 0.002194915898144245 (24800/30729)\n",
            "loss : 0.0015579325845465064 (25600/30729)\n",
            "loss : 0.0032054982148110867 (26400/30729)\n",
            "loss : 0.002053193747997284 (27200/30729)\n",
            "loss : 7.019229087745771e-06 (28000/30729)\n",
            "loss : 0.0032119571696966887 (28800/30729)\n",
            "loss : 0.00324369128793478 (29600/30729)\n",
            "loss : 0.0024732088204473257 (30400/30729)\n",
            "Test loss : 0.0009270973241655156\n",
            "\n",
            "epoch : 9\n",
            "---------------------------\n",
            "loss : 0.0015205126255750656 (0/30729)\n",
            "loss : 0.001855430076830089 (800/30729)\n",
            "loss : 0.0002542530419304967 (1600/30729)\n",
            "loss : 0.002733585424721241 (2400/30729)\n",
            "loss : 0.002009481657296419 (3200/30729)\n",
            "loss : 0.002414545975625515 (4000/30729)\n",
            "loss : 0.0004064689564984292 (4800/30729)\n",
            "loss : 0.0017168850172311068 (5600/30729)\n",
            "loss : 0.00046648879651911557 (6400/30729)\n",
            "loss : 0.004256611689925194 (7200/30729)\n",
            "loss : 0.004629692528396845 (8000/30729)\n",
            "loss : 0.0018929149955511093 (8800/30729)\n",
            "loss : 0.002678163815289736 (9600/30729)\n",
            "loss : 0.001493076328188181 (10400/30729)\n",
            "loss : 0.001990493154153228 (11200/30729)\n",
            "loss : 0.002216959837824106 (12000/30729)\n",
            "loss : 0.0010098428465425968 (12800/30729)\n",
            "loss : 0.0006994798895902932 (13600/30729)\n",
            "loss : 0.003818161552771926 (14400/30729)\n",
            "loss : 0.0032776514999568462 (15200/30729)\n",
            "loss : 0.0012118953745812178 (16000/30729)\n",
            "loss : 0.00011145855387439951 (16800/30729)\n",
            "loss : 0.00036222257767803967 (17600/30729)\n",
            "loss : 0.0020177853293716908 (18400/30729)\n",
            "loss : 0.0010372359538450837 (19200/30729)\n",
            "loss : 0.00181931525003165 (20000/30729)\n",
            "loss : 0.0010212647030130029 (20800/30729)\n",
            "loss : 0.0024566897191107273 (21600/30729)\n",
            "loss : 0.0030031767673790455 (22400/30729)\n",
            "loss : 0.003920318558812141 (23200/30729)\n",
            "loss : 0.000878534687217325 (24000/30729)\n",
            "loss : 0.002154252026230097 (24800/30729)\n",
            "loss : 0.001511013600975275 (25600/30729)\n",
            "loss : 0.003138774773105979 (26400/30729)\n",
            "loss : 0.002055852673947811 (27200/30729)\n",
            "loss : 7.2932739385578316e-06 (28000/30729)\n",
            "loss : 0.00317553011700511 (28800/30729)\n",
            "loss : 0.0031254133209586143 (29600/30729)\n",
            "loss : 0.0024454747326672077 (30400/30729)\n",
            "Test loss : 0.0008769662817940116\n",
            "\n",
            "epoch : 10\n",
            "---------------------------\n",
            "loss : 0.0014890898019075394 (0/30729)\n",
            "loss : 0.0018914798274636269 (800/30729)\n",
            "loss : 0.00024946045596152544 (1600/30729)\n",
            "loss : 0.0027059181593358517 (2400/30729)\n",
            "loss : 0.0020074467174708843 (3200/30729)\n",
            "loss : 0.0025871056132018566 (4000/30729)\n",
            "loss : 0.00040310091571882367 (4800/30729)\n",
            "loss : 0.0017810752615332603 (5600/30729)\n",
            "loss : 0.00044272461673244834 (6400/30729)\n",
            "loss : 0.004150555469095707 (7200/30729)\n",
            "loss : 0.0044413236901164055 (8000/30729)\n",
            "loss : 0.0018693073652684689 (8800/30729)\n",
            "loss : 0.002687241183593869 (9600/30729)\n",
            "loss : 0.001380233676172793 (10400/30729)\n",
            "loss : 0.002153321634978056 (11200/30729)\n",
            "loss : 0.0022110918071120977 (12000/30729)\n",
            "loss : 0.0010733612580224872 (12800/30729)\n",
            "loss : 0.0006978571182116866 (13600/30729)\n",
            "loss : 0.0036375655326992273 (14400/30729)\n",
            "loss : 0.0031926240772008896 (15200/30729)\n",
            "loss : 0.0011540756095200777 (16000/30729)\n",
            "loss : 0.00011432075552875176 (16800/30729)\n",
            "loss : 0.0003433910314925015 (17600/30729)\n",
            "loss : 0.0020549031905829906 (18400/30729)\n",
            "loss : 0.0010692925425246358 (19200/30729)\n",
            "loss : 0.0017916618380695581 (20000/30729)\n",
            "loss : 0.00100662000477314 (20800/30729)\n",
            "loss : 0.002505894284695387 (21600/30729)\n",
            "loss : 0.0029640449211001396 (22400/30729)\n",
            "loss : 0.003919284790754318 (23200/30729)\n",
            "loss : 0.0009031449444591999 (24000/30729)\n",
            "loss : 0.002122157486155629 (24800/30729)\n",
            "loss : 0.0016901982016861439 (25600/30729)\n",
            "loss : 0.003149924799799919 (26400/30729)\n",
            "loss : 0.0020467527210712433 (27200/30729)\n",
            "loss : 6.152031346573494e-06 (28000/30729)\n",
            "loss : 0.003083194838836789 (28800/30729)\n",
            "loss : 0.0030819294042885303 (29600/30729)\n",
            "loss : 0.0024005696177482605 (30400/30729)\n",
            "Test loss : 0.0008740670455154032\n",
            "\n",
            "epoch : 11\n",
            "---------------------------\n",
            "loss : 0.0014419108629226685 (0/30729)\n",
            "loss : 0.0019849338568747044 (800/30729)\n",
            "loss : 0.0002503571449778974 (1600/30729)\n",
            "loss : 0.002704374259337783 (2400/30729)\n",
            "loss : 0.0020141536369919777 (3200/30729)\n",
            "loss : 0.002303351880982518 (4000/30729)\n",
            "loss : 0.00037237993092276156 (4800/30729)\n",
            "loss : 0.0016943872906267643 (5600/30729)\n",
            "loss : 0.0004234257503412664 (6400/30729)\n",
            "loss : 0.004134781192988157 (7200/30729)\n",
            "loss : 0.004439214244484901 (8000/30729)\n",
            "loss : 0.0018849163316190243 (8800/30729)\n",
            "loss : 0.0026435661129653454 (9600/30729)\n",
            "loss : 0.0013244980946183205 (10400/30729)\n",
            "loss : 0.0019387861248105764 (11200/30729)\n",
            "loss : 0.002144288970157504 (12000/30729)\n",
            "loss : 0.0010075048776343465 (12800/30729)\n",
            "loss : 0.0006906995549798012 (13600/30729)\n",
            "loss : 0.003597291186451912 (14400/30729)\n",
            "loss : 0.003084711264818907 (15200/30729)\n",
            "loss : 0.00100357411429286 (16000/30729)\n",
            "loss : 9.2754875367973e-05 (16800/30729)\n",
            "loss : 0.0003455875557847321 (17600/30729)\n",
            "loss : 0.0018938102293759584 (18400/30729)\n",
            "loss : 0.0010057736653834581 (19200/30729)\n",
            "loss : 0.0016931399004533887 (20000/30729)\n",
            "loss : 0.0009766144212335348 (20800/30729)\n",
            "loss : 0.0023922924883663654 (21600/30729)\n",
            "loss : 0.0029492899775505066 (22400/30729)\n",
            "loss : 0.003903099801391363 (23200/30729)\n",
            "loss : 0.0008737766183912754 (24000/30729)\n",
            "loss : 0.002055923920124769 (24800/30729)\n",
            "loss : 0.001586758065968752 (25600/30729)\n",
            "loss : 0.003025958314538002 (26400/30729)\n",
            "loss : 0.0020645642653107643 (27200/30729)\n",
            "loss : 8.605292350694072e-06 (28000/30729)\n",
            "loss : 0.0030232411809265614 (28800/30729)\n",
            "loss : 0.002990648616105318 (29600/30729)\n",
            "loss : 0.0023068098817020655 (30400/30729)\n",
            "Test loss : 0.0008476329530822113\n",
            "\n",
            "epoch : 12\n",
            "---------------------------\n",
            "loss : 0.0013118770439177752 (0/30729)\n",
            "loss : 0.0019476505694910884 (800/30729)\n",
            "loss : 0.0002714279689826071 (1600/30729)\n",
            "loss : 0.002653703326359391 (2400/30729)\n",
            "loss : 0.002030294155701995 (3200/30729)\n",
            "loss : 0.0022648153826594353 (4000/30729)\n",
            "loss : 0.00039740282227285206 (4800/30729)\n",
            "loss : 0.0016055270098149776 (5600/30729)\n",
            "loss : 0.0004340214654803276 (6400/30729)\n",
            "loss : 0.004210484679788351 (7200/30729)\n",
            "loss : 0.004467325285077095 (8000/30729)\n",
            "loss : 0.001852883375249803 (8800/30729)\n",
            "loss : 0.0026861275546252728 (9600/30729)\n",
            "loss : 0.001286754384636879 (10400/30729)\n",
            "loss : 0.001964178401976824 (11200/30729)\n",
            "loss : 0.0021088423673063517 (12000/30729)\n",
            "loss : 0.0010117278434336185 (12800/30729)\n",
            "loss : 0.0006899549625813961 (13600/30729)\n",
            "loss : 0.0035132949706166983 (14400/30729)\n",
            "loss : 0.003048623912036419 (15200/30729)\n",
            "loss : 0.000997044495306909 (16000/30729)\n",
            "loss : 9.17816796572879e-05 (16800/30729)\n",
            "loss : 0.0003509382950142026 (17600/30729)\n",
            "loss : 0.0018080880399793386 (18400/30729)\n",
            "loss : 0.00104375253431499 (19200/30729)\n",
            "loss : 0.001655123895034194 (20000/30729)\n",
            "loss : 0.0009560128091834486 (20800/30729)\n",
            "loss : 0.002328581875190139 (21600/30729)\n",
            "loss : 0.0026502683758735657 (22400/30729)\n",
            "loss : 0.0038615541998296976 (23200/30729)\n",
            "loss : 0.0008550447528250515 (24000/30729)\n",
            "loss : 0.0020248116925358772 (24800/30729)\n",
            "loss : 0.001610748702660203 (25600/30729)\n",
            "loss : 0.002939485711976886 (26400/30729)\n",
            "loss : 0.002044317312538624 (27200/30729)\n",
            "loss : 7.537305009464035e-06 (28000/30729)\n",
            "loss : 0.0029703215695917606 (28800/30729)\n",
            "loss : 0.0029752347618341446 (29600/30729)\n",
            "loss : 0.0023068971931934357 (30400/30729)\n",
            "Test loss : 0.0008149751229211688\n",
            "\n",
            "epoch : 13\n",
            "---------------------------\n",
            "loss : 0.0013646334409713745 (0/30729)\n",
            "loss : 0.0019191589672118425 (800/30729)\n",
            "loss : 0.00026240223087370396 (1600/30729)\n",
            "loss : 0.002622472122311592 (2400/30729)\n",
            "loss : 0.002041528932750225 (3200/30729)\n",
            "loss : 0.0027139312587678432 (4000/30729)\n",
            "loss : 0.0004224211152177304 (4800/30729)\n",
            "loss : 0.0017009384464472532 (5600/30729)\n",
            "loss : 0.0004228781908750534 (6400/30729)\n",
            "loss : 0.0040796007961034775 (7200/30729)\n",
            "loss : 0.004420630633831024 (8000/30729)\n",
            "loss : 0.0018242222722619772 (8800/30729)\n",
            "loss : 0.0026396908797323704 (9600/30729)\n",
            "loss : 0.0012923007598146796 (10400/30729)\n",
            "loss : 0.0018685440300032496 (11200/30729)\n",
            "loss : 0.002082420513033867 (12000/30729)\n",
            "loss : 0.0010035643354058266 (12800/30729)\n",
            "loss : 0.0006776713998988271 (13600/30729)\n",
            "loss : 0.003326450940221548 (14400/30729)\n",
            "loss : 0.002980258781462908 (15200/30729)\n",
            "loss : 0.0009621742647141218 (16000/30729)\n",
            "loss : 9.424597374163568e-05 (16800/30729)\n",
            "loss : 0.000385013670893386 (17600/30729)\n",
            "loss : 0.0017912588082253933 (18400/30729)\n",
            "loss : 0.0009925089543685317 (19200/30729)\n",
            "loss : 0.001653108629398048 (20000/30729)\n",
            "loss : 0.0009532661642879248 (20800/30729)\n",
            "loss : 0.0022990494035184383 (21600/30729)\n",
            "loss : 0.0026283988263458014 (22400/30729)\n",
            "loss : 0.003879137570038438 (23200/30729)\n",
            "loss : 0.000824860529974103 (24000/30729)\n",
            "loss : 0.0019962491933256388 (24800/30729)\n",
            "loss : 0.0014222434256225824 (25600/30729)\n",
            "loss : 0.002874143421649933 (26400/30729)\n",
            "loss : 0.002034088596701622 (27200/30729)\n",
            "loss : 1.1323832950438373e-05 (28000/30729)\n",
            "loss : 0.0029073525220155716 (28800/30729)\n",
            "loss : 0.0028708672616630793 (29600/30729)\n",
            "loss : 0.0022584092803299427 (30400/30729)\n",
            "Test loss : 0.000797713131760247\n",
            "\n",
            "epoch : 14\n",
            "---------------------------\n",
            "loss : 0.0012454944662749767 (0/30729)\n",
            "loss : 0.0018228428671136498 (800/30729)\n",
            "loss : 0.00027012164355255663 (1600/30729)\n",
            "loss : 0.0025664526037871838 (2400/30729)\n",
            "loss : 0.002046627225354314 (3200/30729)\n",
            "loss : 0.002224439289420843 (4000/30729)\n",
            "loss : 0.00037990370765328407 (4800/30729)\n",
            "loss : 0.0015680204378440976 (5600/30729)\n",
            "loss : 0.00042685004882514477 (6400/30729)\n",
            "loss : 0.0041403332725167274 (7200/30729)\n",
            "loss : 0.004273948259651661 (8000/30729)\n",
            "loss : 0.0018044003518298268 (8800/30729)\n",
            "loss : 0.0025988705456256866 (9600/30729)\n",
            "loss : 0.0012281965464353561 (10400/30729)\n",
            "loss : 0.002037706784904003 (11200/30729)\n",
            "loss : 0.0021078314166516066 (12000/30729)\n",
            "loss : 0.0010224025463685393 (12800/30729)\n",
            "loss : 0.0006761371623724699 (13600/30729)\n",
            "loss : 0.0033108012285083532 (14400/30729)\n",
            "loss : 0.0029488832224160433 (15200/30729)\n",
            "loss : 0.0009303201222792268 (16000/30729)\n",
            "loss : 8.467849693261087e-05 (16800/30729)\n",
            "loss : 0.0004023756773676723 (17600/30729)\n",
            "loss : 0.001750375609844923 (18400/30729)\n",
            "loss : 0.0010000972542911768 (19200/30729)\n",
            "loss : 0.0016350807854905725 (20000/30729)\n",
            "loss : 0.0009376711677759886 (20800/30729)\n",
            "loss : 0.0022360130678862333 (21600/30729)\n",
            "loss : 0.0025634646881371737 (22400/30729)\n",
            "loss : 0.0038569392636418343 (23200/30729)\n",
            "loss : 0.0008068780298344791 (24000/30729)\n",
            "loss : 0.002012765035033226 (24800/30729)\n",
            "loss : 0.001443411922082305 (25600/30729)\n",
            "loss : 0.0028372660744935274 (26400/30729)\n",
            "loss : 0.002033091615885496 (27200/30729)\n",
            "loss : 9.675330147729255e-06 (28000/30729)\n",
            "loss : 0.0028830785304307938 (28800/30729)\n",
            "loss : 0.002854722086340189 (29600/30729)\n",
            "loss : 0.0022386275231838226 (30400/30729)\n",
            "Test loss : 0.0007823705673217773\n",
            "\n",
            "epoch : 15\n",
            "---------------------------\n",
            "loss : 0.0011943825520575047 (0/30729)\n",
            "loss : 0.0017554099904373288 (800/30729)\n",
            "loss : 0.0002652688999660313 (1600/30729)\n",
            "loss : 0.002552497899159789 (2400/30729)\n",
            "loss : 0.002018001629039645 (3200/30729)\n",
            "loss : 0.002125402679666877 (4000/30729)\n",
            "loss : 0.000370387511793524 (4800/30729)\n",
            "loss : 0.0015143699711188674 (5600/30729)\n",
            "loss : 0.00042587562347762287 (6400/30729)\n",
            "loss : 0.0040743849240243435 (7200/30729)\n",
            "loss : 0.004151271656155586 (8000/30729)\n",
            "loss : 0.0017717999871820211 (8800/30729)\n",
            "loss : 0.0025321240536868572 (9600/30729)\n",
            "loss : 0.001201108330860734 (10400/30729)\n",
            "loss : 0.0020194605458527803 (11200/30729)\n",
            "loss : 0.002017510123550892 (12000/30729)\n",
            "loss : 0.0010227581951767206 (12800/30729)\n",
            "loss : 0.0006799772381782532 (13600/30729)\n",
            "loss : 0.0031993663869798183 (14400/30729)\n",
            "loss : 0.002927046734839678 (15200/30729)\n",
            "loss : 0.0009291038732044399 (16000/30729)\n",
            "loss : 8.129607158480212e-05 (16800/30729)\n",
            "loss : 0.0003949932288378477 (17600/30729)\n",
            "loss : 0.0017362399958074093 (18400/30729)\n",
            "loss : 0.0009763492271304131 (19200/30729)\n",
            "loss : 0.0016300370916724205 (20000/30729)\n",
            "loss : 0.0009354610810987651 (20800/30729)\n",
            "loss : 0.0022089809644967318 (21600/30729)\n",
            "loss : 0.002562990179285407 (22400/30729)\n",
            "loss : 0.00382577208802104 (23200/30729)\n",
            "loss : 0.0008018139633350074 (24000/30729)\n",
            "loss : 0.0019646254368126392 (24800/30729)\n",
            "loss : 0.0014870798913761973 (25600/30729)\n",
            "loss : 0.002797410823404789 (26400/30729)\n",
            "loss : 0.0020211946684867144 (27200/30729)\n",
            "loss : 7.493343218811788e-06 (28000/30729)\n",
            "loss : 0.0028197907377034426 (28800/30729)\n",
            "loss : 0.002847425639629364 (29600/30729)\n",
            "loss : 0.002218242734670639 (30400/30729)\n",
            "Test loss : 0.0007749415963189676\n",
            "\n",
            "epoch : 16\n",
            "---------------------------\n",
            "loss : 0.0011550318449735641 (0/30729)\n",
            "loss : 0.0017604728927835822 (800/30729)\n",
            "loss : 0.0002613062970340252 (1600/30729)\n",
            "loss : 0.0025944074150174856 (2400/30729)\n",
            "loss : 0.001998698338866234 (3200/30729)\n",
            "loss : 0.0020767131354659796 (4000/30729)\n",
            "loss : 0.00037273167981766164 (4800/30729)\n",
            "loss : 0.001489348360337317 (5600/30729)\n",
            "loss : 0.0004260937566868961 (6400/30729)\n",
            "loss : 0.00399436429142952 (7200/30729)\n",
            "loss : 0.00408164830878377 (8000/30729)\n",
            "loss : 0.0017642872408032417 (8800/30729)\n",
            "loss : 0.0025047422386705875 (9600/30729)\n",
            "loss : 0.0011923668207600713 (10400/30729)\n",
            "loss : 0.0019427102524787188 (11200/30729)\n",
            "loss : 0.001993062673136592 (12000/30729)\n",
            "loss : 0.0010025757364928722 (12800/30729)\n",
            "loss : 0.0006760734831914306 (13600/30729)\n",
            "loss : 0.0031101852655410767 (14400/30729)\n",
            "loss : 0.002880675019696355 (15200/30729)\n",
            "loss : 0.0009145071962848306 (16000/30729)\n",
            "loss : 8.405142580159009e-05 (16800/30729)\n",
            "loss : 0.00037907803198322654 (17600/30729)\n",
            "loss : 0.0017095244256779552 (18400/30729)\n",
            "loss : 0.0009657451882958412 (19200/30729)\n",
            "loss : 0.001619506161659956 (20000/30729)\n",
            "loss : 0.0009431185899302363 (20800/30729)\n",
            "loss : 0.0022159162908792496 (21600/30729)\n",
            "loss : 0.0025885498616844416 (22400/30729)\n",
            "loss : 0.0038534505292773247 (23200/30729)\n",
            "loss : 0.0007865294464863837 (24000/30729)\n",
            "loss : 0.0019740057177841663 (24800/30729)\n",
            "loss : 0.001480537699535489 (25600/30729)\n",
            "loss : 0.002831116085872054 (26400/30729)\n",
            "loss : 0.0020152076613157988 (27200/30729)\n",
            "loss : 5.892032277188264e-06 (28000/30729)\n",
            "loss : 0.0028199399821460247 (28800/30729)\n",
            "loss : 0.0028418549336493015 (29600/30729)\n",
            "loss : 0.0021755765192210674 (30400/30729)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-f62cf9f323ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-4e7c88084518>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-d6930ecc2852>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mbase_music\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mbase_music\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_music\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mbase_music\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase_music\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    441\u001b[0m                                          pickle_kwargs=pickle_kwargs)\n\u001b[1;32m    442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 30\n",
        "for t in range(epochs):\n",
        "    print(f\"epoch : {t+1}\\n---------------------------\")\n",
        "    model.train()\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "8dzB0UYOQzb4"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/model2.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "y2HN_gCzsZDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f10e66-4fd9-4306-db86-1d4f3065e7cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "model_load = WaveUNet().to(device)\n",
        "model_load.load_state_dict(torch.load(\"/content/gdrive/MyDrive/model2.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_arr = torch.Tensor(test_ds[0][0]).to(device)"
      ],
      "metadata": {
        "id": "KBtXOBLlBR47"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_arr = torch.unsqueeze(test_arr, 0)"
      ],
      "metadata": {
        "id": "0AIOvfqnBZTn"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "5rvETVMoq4ue"
      },
      "outputs": [],
      "source": [
        "model_load.eval()\n",
        "with torch.no_grad():\n",
        "    pred = model_load(test_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "U_GFvF0QLzsK"
      },
      "outputs": [],
      "source": [
        "def write(f, sr, x, normalized=False):\n",
        "    \"\"\"numpy array to MP3\"\"\"\n",
        "    channels = 2 if (x.ndim == 2 and x.shape[1] == 2) else 1\n",
        "    if normalized:  # normalized array - each item should be a float in [-1, 1)\n",
        "        y = np.int16(x * 2 ** 15)\n",
        "    else:\n",
        "        y = np.int16(x)\n",
        "    song = pydub.AudioSegment(x.tobytes(), frame_rate=sr, sample_width=2, channels=1)\n",
        "    song.export(f, format=\"mp3\", bitrate=\"320k\")\n",
        "\n",
        "# write('/content/gdrive/MyDrive/test.mp3', 22050, np.array(splittest[0][0].cpu()), normalized=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_ds[0][1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Iuh1knGduhYM",
        "outputId": "ddef9fd2-4b57-4113-dff3-ff018d222a0d"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd419c7c280>]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "0yRGTEAPsbxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1a3619d8-f887-4c30-d610-526bfc91ae52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd413392b80>]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(pred[0][0].cpu())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile\n",
        "\n",
        "soundfile.write('/content/gdrive/MyDrive/model_out/test0.wav', \n",
        "                test_ds[0][1][0], \n",
        "                22050, \n",
        "                format='wav')\n",
        "\n",
        "soundfile.write('/content/gdrive/MyDrive/model_out/test0_out.wav', \n",
        "                pred[0][0].cpu(), \n",
        "                22050, \n",
        "                format='wav')"
      ],
      "metadata": {
        "id": "SLZkuDBaCgfu"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ohw-xSC9ufG2"
      },
      "outputs": [],
      "source": [
        "write('/content/gdrive/MyDrive/test2.mp3', 22050, test_ds[0][1][1], normalized=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP8rm2DnvYfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d810547d-b532-4b5d-b355-c1af1c643c5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.1242e-03, -5.1037e-03, -6.8920e-03,  ..., -9.6870e-04,\n",
              "         -8.3271e-04, -6.1841e-04],\n",
              "        [-4.6458e-03, -9.0684e-03, -1.3509e-02,  ...,  1.0061e-01,\n",
              "          8.9305e-02,  8.5974e-02],\n",
              "        [-5.0559e-03, -1.2085e-02, -2.0577e-02,  ..., -5.6188e-04,\n",
              "         -4.4316e-04, -6.3813e-05],\n",
              "        [-2.3955e-03, -6.8933e-03, -1.3077e-02,  ..., -2.9201e-04,\n",
              "         -3.5774e-04, -3.2391e-04]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "pred[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('soundprocessing')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "a5bbe51b3405e60c087d18985c6a5d36133bee8e93b3430261fcdb872e4da9e2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}