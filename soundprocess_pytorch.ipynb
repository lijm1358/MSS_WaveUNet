{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijm1358/anaconda3/envs/soundprocessing/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MUSDBDataset(Dataset):\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.crop_size = 284672\n",
    "        self.data_dir = os.path.join(data_dir, 'data_numpy')\n",
    "        if not os.path.exists(self.data_dir) or \\\n",
    "            len([name for name in os.listdir(self.data_dir)]) < 500:\n",
    "            print(\"Data has not been saved as numpy object. Converting...\")\n",
    "            if not os.path.exists(self.data_dir):\n",
    "                os.makedirs(self.data_dir)\n",
    "            self.convert_to_numpy(data_dir, self.data_dir)\n",
    "        self.music_fulllist = self.get_filenames(self.data_dir)\n",
    "        self.music_list, self.sep_list = self.separate_source(self.music_fulllist)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.music_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_music = self.music_list[idx]\n",
    "        base_music = np.load(base_music)\n",
    "        base_music = np.stack([base_music[:self.crop_size]])\n",
    "\n",
    "        sep_music = self.sep_list[idx*4 : idx*4+4]\n",
    "        sep_music = np.stack([np.load(idx)[:self.crop_size] for idx in sep_music])\n",
    "        return base_music, sep_music\n",
    "\n",
    "    def get_filenames(self, path):\n",
    "        files_list = list()\n",
    "        for filename in os.listdir(path):\n",
    "            if not filename == \"data_numpy\":\n",
    "                files_list.append(os.path.join(path, filename))\n",
    "        return files_list\n",
    "\n",
    "    def convert_to_numpy(self, music_dir, target_dir):\n",
    "        warnings.filterwarnings('ignore')\n",
    "        music_list = self.get_filenames(music_dir)\n",
    "        for music in tqdm(music_list):\n",
    "            outfile_name = music.split(\"/\")[-1]\n",
    "            outfile_name = target_dir + \"/\" + outfile_name\n",
    "            arr, _ = librosa.load(music)\n",
    "            np.save(outfile_name, arr)\n",
    "\n",
    "    def separate_source(self, mus_list):\n",
    "        warnings.filterwarnings('ignore')\n",
    "        music_list = list()\n",
    "        sep_list = list()\n",
    "        for music in tqdm(mus_list):\n",
    "            mus_type = music.split(\".\")[-3]\n",
    "            if mus_type == '0':\n",
    "                music_list.append(music)\n",
    "            else:\n",
    "                sep_list.append(music)\n",
    "\n",
    "        return music_list, sep_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 1150385.08it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = MUSDBDataset('/mnt/d/createdmusdb18/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io.wavfile import write\n",
    "# data = sample\n",
    "# scaled = np.int16(data/np.max(np.abs(data)) * 32767)\n",
    "# write('/mnt/c/Users/lijm1/Desktop/test.wav', 22050, scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(ds, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.waveunet import Waveunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [32*2**i for i in range(0, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import model.utils as model_utils\n",
    "import utils\n",
    "from data.dataset import SeparationDataset\n",
    "# from data.musdb import get_musdb_folds\n",
    "# from data.utils import crop_targets, random_amplify\n",
    "# from test import evaluate, validate\n",
    "from model.waveunet import Waveunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using valid convolutions with 42665 inputs and 33113 outputs\n",
      "move model to gpu\n",
      "model:  DataParallel(\n",
      "  (module): Waveunet(\n",
      "    (waveunets): ModuleDict(\n",
      "      (bass): Module(\n",
      "        (downsampling_blocks): ModuleList(\n",
      "          (0): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (1): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (2): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (3): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (4): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "        )\n",
      "        (upsampling_blocks): ModuleList(\n",
      "          (0): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (bottlenecks): ModuleList(\n",
      "          (0): ConvLayer(\n",
      "            (filter): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
      "            (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (output_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (drums): Module(\n",
      "        (downsampling_blocks): ModuleList(\n",
      "          (0): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (1): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (2): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (3): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (4): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "        )\n",
      "        (upsampling_blocks): ModuleList(\n",
      "          (0): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (bottlenecks): ModuleList(\n",
      "          (0): ConvLayer(\n",
      "            (filter): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
      "            (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (output_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (other): Module(\n",
      "        (downsampling_blocks): ModuleList(\n",
      "          (0): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (1): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (2): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (3): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (4): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "        )\n",
      "        (upsampling_blocks): ModuleList(\n",
      "          (0): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (bottlenecks): ModuleList(\n",
      "          (0): ConvLayer(\n",
      "            (filter): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
      "            (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (output_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (vocals): Module(\n",
      "        (downsampling_blocks): ModuleList(\n",
      "          (0): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (1): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (2): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (3): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (4): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "        )\n",
      "        (upsampling_blocks): ModuleList(\n",
      "          (0): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (bottlenecks): ModuleList(\n",
      "          (0): ConvLayer(\n",
      "            (filter): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
      "            (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (output_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "parameter count:  70147460\n"
     ]
    }
   ],
   "source": [
    "model = Waveunet(1, num_features, 1, [\"bass\", \"drums\", \"other\", \"vocals\"], kernel_size=5,\n",
    "                     target_output_size=32425, depth=1, strides=4,\n",
    "                     conv_type=\"gn\", res=\"fixed\", separate=1)\n",
    "\n",
    "model = model_utils.DataParallel(model)\n",
    "print(\"move model to gpu\")\n",
    "model.cuda()\n",
    "\n",
    "print('model: ', model)\n",
    "print('parameter count: ', str(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284672,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand(42665,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/soundprocessing/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git-repo/Wave-U-Net-Pytorch/model/waveunet.py:225\u001b[0m, in \u001b[0;36mWaveunet.forward\u001b[0;34m(self, x, inst)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39massert\u001b[39;00m(curr_input_size \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size) \u001b[39m# User promises to feed the proper input himself, to get the pre-calculated (NOT the originally desired) output size\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseparate:\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mreturn\u001b[39;00m {inst : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_module(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwaveunets[inst])}\n\u001b[1;32m    226\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaveunets) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/soundprocessing/lib/python3.8/site-packages/torch/nn/modules/container.py:326\u001b[0m, in \u001b[0;36mModuleDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m@_copy_to_script_wrapper\u001b[39m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Module:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modules[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "model(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        input_channels: int = 3,\n",
    "        num_layers: int = 5,\n",
    "        features_start: int = 64,\n",
    "        bilinear: bool = False,\n",
    "    ):\n",
    "\n",
    "        if num_layers < 1:\n",
    "            raise ValueError(f\"num_layers = {num_layers}, expected: num_layers > 0\")\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        layers = [DoubleConv(input_channels, features_start)]\n",
    "\n",
    "        feats = features_start\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(Down(feats, feats * 2))\n",
    "            feats *= 2\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(Up(feats, feats // 2, bilinear))\n",
    "            feats //= 2\n",
    "\n",
    "        layers.append(nn.Conv2d(feats, num_classes, kernel_size=1))\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        xi = [self.layers[0](x)]\n",
    "        # Down path\n",
    "        for layer in self.layers[1 : self.num_layers]:\n",
    "            xi.append(layer(xi[-1]))\n",
    "        # Up path\n",
    "        for i, layer in enumerate(self.layers[self.num_layers : -1]):\n",
    "            xi[-1] = layer(xi[-1], xi[-2 - i])\n",
    "        return self.layers[-1](xi[-1])\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"[ Conv2d => BatchNorm => ReLU ] x 2.\"\"\"\n",
    "\n",
    "    def __init__(self, in_ch: int, out_ch: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscale with MaxPool => DoubleConvolution block.\"\"\"\n",
    "\n",
    "    def __init__(self, in_ch: int, out_ch: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.MaxPool1d(kernel_size=2, stride=2), DoubleConv(in_ch, out_ch))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upsampling (by either bilinear interpolation or transpose convolutions) followed by concatenation of feature\n",
    "    map from contracting path, followed by DoubleConv.\"\"\"\n",
    "\n",
    "    def __init__(self, in_ch: int, out_ch: int, bilinear: bool = False):\n",
    "        super().__init__()\n",
    "        self.upsample = None\n",
    "        if bilinear:\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True),\n",
    "                nn.Conv2d(in_ch, in_ch // 2, kernel_size=1),\n",
    "            )\n",
    "        else:\n",
    "            self.upsample = nn.ConvTranspose2d(in_ch, in_ch // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1: Tensor, x2: Tensor) -> Tensor:\n",
    "        x1 = self.upsample(x1)\n",
    "\n",
    "        # Pad x1 to the size of x2\n",
    "        diff_h = x2.shape[2] - x1.shape[2]\n",
    "        diff_w = x2.shape[3] - x1.shape[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diff_w // 2, diff_w - diff_w // 2, diff_h // 2, diff_h - diff_h // 2])\n",
    "\n",
    "        # Concatenate along the channels axis\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = DoubleConv(in_ch = 1, out_ch = 64)\n",
    "layer2 = Down(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 284672])\n",
      "torch.Size([4, 32, 142336])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    out = layer(x)\n",
    "    print(out.shape)\n",
    "    out = layer2(out)\n",
    "    print(out.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('soundprocessing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5bbe51b3405e60c087d18985c6a5d36133bee8e93b3430261fcdb872e4da9e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
